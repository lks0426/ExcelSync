#!/usr/bin/env python3
"""
ExcelSyncé¡¹ç›®çš„ä¸»æ¨¡å—
ç®€å•å®ç°ï¼šJSONè¾“å…¥ â†’ Excelè¾“å‡º
"""

import json
import logging
from pathlib import Path
from typing import Dict, Any
from datetime import datetime
import shutil

from excel_writer import ExcelWriter
from data_validator import prepare_api_data
from mapping_config import TRIAL_BALANCE_MAPPING

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('excel_sync.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class ExcelSync:
    """
    ç®€å•çš„JSONåˆ°ExcelåŒæ­¥å™¨
    """
    
    def __init__(self, excel_path: str = "mapping.xlsx", sheet_name: str = "Aç¤¾è²¼ã‚Šä»˜ã‘BS"):
        """
        åˆå§‹åŒ–ExcelSync
        
        å‚æ•°:
            excel_path: Excelæ–‡ä»¶è·¯å¾„
            sheet_name: å·¥ä½œè¡¨åç§°
        """
        self.excel_path = excel_path
        self.sheet_name = sheet_name
        self.writer = ExcelWriter(excel_path, sheet_name)
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        self.output_dir = Path("output")
        self.output_dir.mkdir(exist_ok=True)
        
    def sync_from_json_file(self, json_path: str) -> Dict[str, Any]:
        """
        ä»JSONæ–‡ä»¶è¯»å–æ•°æ®å¹¶å†™å…¥Excel
        
        å‚æ•°:
            json_path: JSONæ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            åŒæ­¥ç»“æœå­—å…¸
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            # è¯»å–JSONæ•°æ®
            logger.info(f"è¯»å–JSONæ–‡ä»¶: {json_path}")
            with open(json_path, 'r', encoding='utf-8') as f:
                api_data = json.load(f)
            
            # æ¸…ç†æ•°æ®
            logger.info("æ¸…ç†æ•°æ®...")
            cleaned_data = prepare_api_data(api_data)
            
            # åˆ›å»ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_filename = f"mapping_output_{timestamp}.xlsx"
            output_path = self.output_dir / output_filename
            
            # å¤‡ä»½åŸæ–‡ä»¶åˆ°è¾“å‡ºæ–‡ä»¶å¤¹
            backup_filename = f"mapping_backup_{timestamp}.xlsx"
            backup_path = self.output_dir / backup_filename
            shutil.copy2(self.excel_path, backup_path)
            logger.info(f"å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
            
            # å†™å…¥æ•°æ®åˆ°è¾“å‡ºæ–‡ä»¶
            logger.info("å†™å…¥æ•°æ®åˆ°Excel...")
            result = self.writer.process_api_data(cleaned_data, TRIAL_BALANCE_MAPPING, str(output_path))
            
            # è®¡ç®—æˆåŠŸç‡
            successful_writes = sum(1 for status in result["write_status"].values() 
                                  if status == "success")
            total_fields = len(TRIAL_BALANCE_MAPPING)
            
            result.update({
                "timestamp": timestamp,
                "json_file": json_path,
                "output_file": str(output_path),
                "backup_file": str(backup_path),
                "total_fields": total_fields,
                "successful_writes": successful_writes,
                "success_rate": f"{(successful_writes/total_fields)*100:.1f}%"
            })
            
            if successful_writes == total_fields:
                logger.info(f"åŒæ­¥æˆåŠŸå®Œæˆ: {successful_writes}/{total_fields} å­—æ®µå·²å†™å…¥")
                logger.info(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
            else:
                logger.warning(f"åŒæ­¥éƒ¨åˆ†å®Œæˆ: {successful_writes}/{total_fields} å­—æ®µå·²å†™å…¥")
            
            return result
            
        except FileNotFoundError:
            error_msg = f"æ‰¾ä¸åˆ°JSONæ–‡ä»¶: {json_path}"
            logger.error(error_msg)
            return {"status": "error", "error": error_msg}
        except json.JSONDecodeError as e:
            error_msg = f"JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            return {"status": "error", "error": error_msg}
        except Exception as e:
            error_msg = f"åŒæ­¥å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"status": "error", "error": error_msg}


def main():
    """å•ä¸€ä¸»å‡½æ•° - ä»JSONæ–‡ä»¶åŒæ­¥åˆ°Excel"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ExcelSync - ç®€å•çš„JSONåˆ°Excelæ•°æ®åŒæ­¥å·¥å…·")
    parser.add_argument("json_file", help="åŒ…å«æ•°æ®çš„JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--excel", default="mapping.xlsx", help="Excelæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--sheet", default="Aç¤¾è²¼ã‚Šä»˜ã‘BS", help="å·¥ä½œè¡¨åç§°")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.json_file).exists():
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°JSONæ–‡ä»¶ '{args.json_file}'")
        return 1
    
    # æ‰§è¡ŒåŒæ­¥
    sync = ExcelSync(args.excel, args.sheet)
    result = sync.sync_from_json_file(args.json_file)
    
    # è¾“å‡ºç»“æœ
    print("\n=== åŒæ­¥ç»“æœ ===")
    if result["status"] == "success":
        print(f"âœ… æˆåŠŸ: {result['success_rate']} ({result['successful_writes']}/{result['total_fields']} å­—æ®µ)")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {result['output_file']}")
        print(f"ğŸ”„ å¤‡ä»½æ–‡ä»¶: {result['backup_file']}")
    elif result["status"] == "partial_success":
        print(f"âš ï¸  éƒ¨åˆ†æˆåŠŸ: {result['success_rate']} ({result['successful_writes']}/{result['total_fields']} å­—æ®µ)")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {result['output_file']}")
        print(f"ğŸ”„ å¤‡ä»½æ–‡ä»¶: {result['backup_file']}")
    else:
        print(f"âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    return 0 if result["status"] in ["success", "partial_success"] else 1


if __name__ == "__main__":
    exit(main())