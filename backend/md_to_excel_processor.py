#!/usr/bin/env python3
"""
MDåˆ°Excelå¤„ç†å™¨
å°†Markdownè¡¨æ ¼è§£æå¹¶ç”Ÿæˆå¸¦æœ‰Dåˆ—æ•°æ®çš„Excelæ–‡ä»¶
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

from md_parser import MDParser
from excel_writer import ExcelWriter
from data_validator import prepare_api_data
from mapping_config import TRIAL_BALANCE_MAPPING, CELL_DESCRIPTIONS

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MDToExcelProcessor:
    """
    å¤„ç†MDæ–‡ä»¶åˆ°Excelæ–‡ä»¶çš„å®Œæ•´å·¥ä½œæµç¨‹
    """
    
    def __init__(self, excel_template_path: str = "mapping.xlsx", sheet_name: str = "Aç¤¾è²¼ã‚Šä»˜ã‘BS"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        å‚æ•°:
            excel_template_path: Excelæ¨¡æ¿æ–‡ä»¶è·¯å¾„
            sheet_name: å·¥ä½œè¡¨åç§°
        """
        self.excel_template_path = Path(excel_template_path)
        self.sheet_name = sheet_name
        self.output_dir = Path("output")
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.md_parser = MDParser()
        self.excel_writer = ExcelWriter(str(self.excel_template_path), sheet_name)
        
        # æ„å»ºå®Œæ•´çš„æ—¥æ–‡åˆ°è‹±æ–‡å­—æ®µæ˜ å°„
        self.japanese_to_field_mapping = self._build_japanese_mapping()
        logger.info(f"å·²æ„å»º {len(self.japanese_to_field_mapping)} ä¸ªæ—¥æ–‡åˆ°å­—æ®µçš„æ˜ å°„")
        
    def process_md_content(self, md_content: str, filename: str = "uploaded.md") -> Dict[str, Any]:
        """
        å¤„ç†MDæ–‡æœ¬å†…å®¹å¹¶ç”ŸæˆExcelæ–‡ä»¶
        
        å‚æ•°:
            md_content: Markdownæ–‡æœ¬å†…å®¹
            filename: åŸå§‹æ–‡ä»¶å
            
        è¿”å›:
            å¤„ç†ç»“æœå­—å…¸
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            # è§£æMDå†…å®¹
            logger.info(f"ğŸ” å¼€å§‹è§£æMarkdownå†…å®¹ (æ–‡ä»¶: {filename})...")
            logger.debug(f"MDå†…å®¹é•¿åº¦: {len(md_content)} å­—ç¬¦")
            parsed_result = self.md_parser.parse(md_content)
            logger.info(f"ğŸ“Š MDè§£æå®Œæˆï¼Œå‘ç° {len(parsed_result.get('rows', []))} è¡Œæ•°æ®")
            
            if not parsed_result.get('rows') or len(parsed_result['rows']) == 0:
                logger.error("âŒ MDæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¡¨æ ¼æ•°æ®")
                return {
                    "success": False,
                    "error": "MDæ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¡¨æ ¼æ•°æ®",
                    "stage": "md_parsing"
                }
            
            # å°†è§£æç»“æœè½¬æ¢ä¸ºAPIæ•°æ®æ ¼å¼
            logger.info("ğŸ”„ å°†è§£æç»“æœè½¬æ¢ä¸ºAPIæ•°æ®æ ¼å¼...")
            api_data = self._convert_md_to_api_data(parsed_result)
            logger.info(f"âœ… è½¬æ¢å®Œæˆï¼Œæ•°æ®åŒ…å« {len(api_data)} ä¸ªå­—æ®µ")
            
            # æ¸…ç†å’ŒéªŒè¯æ•°æ®
            logger.info("ğŸ§¹ æ¸…ç†å’ŒéªŒè¯æ•°æ®...")
            cleaned_data = prepare_api_data(api_data)
            logger.info(f"âœ… æ•°æ®æ¸…ç†å®Œæˆï¼Œæ¸…ç†åæ•°æ®: {len(cleaned_data)} ä¸ªå­—æ®µ")
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            base_name = Path(filename).stem
            output_filename = f"{base_name}_output_{timestamp}.xlsx"
            output_path = self.output_dir / output_filename
            logger.info(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶è·¯å¾„: {output_path}")
            
            # ä½¿ç”¨Excelå†™å…¥å™¨å¤„ç†æ•°æ®
            logger.info("ğŸ“ å¼€å§‹ç”ŸæˆExcelæ–‡ä»¶...")
            excel_result = self.excel_writer.process_api_data(
                cleaned_data, 
                TRIAL_BALANCE_MAPPING, 
                str(output_path)
            )
            logger.info(f"ğŸ“Š Excelå†™å…¥å®Œæˆï¼ŒçŠ¶æ€: {excel_result['status']}")
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            successful_writes = sum(1 for status in excel_result["write_status"].values() 
                                  if status == "success")
            total_fields = len(TRIAL_BALANCE_MAPPING)
            
            # å‡†å¤‡è¿”å›ç»“æœ
            result = {
                "success": excel_result["status"] in ["success", "partial_success"],
                "timestamp": timestamp,
                "input_filename": filename,
                "output_filename": output_filename,
                "output_path": str(output_path),
                "stage": "completed",
                
                # MDè§£æä¿¡æ¯
                "md_parsing": {
                    "headers": parsed_result.get('headers', []),
                    "rows_count": len(parsed_result.get('rows', [])),
                    "metadata": parsed_result.get('metadata', {})
                },
                
                # Excelå†™å…¥ä¿¡æ¯
                "excel_writing": {
                    "status": excel_result["status"],
                    "total_fields": total_fields,
                    "successful_writes": successful_writes,
                    "success_rate": f"{(successful_writes/total_fields)*100:.1f}%",
                    "write_status": excel_result["write_status"],
                    "mapping_valid": excel_result["mapping_valid"]
                },
                
                # é”™è¯¯ä¿¡æ¯
                "errors": excel_result.get("errors", [])
            }
            
            if result["success"]:
                logger.info(f"å¤„ç†æˆåŠŸå®Œæˆ: {output_filename}")
                logger.info(f"Excelå†™å…¥æˆåŠŸç‡: {result['excel_writing']['success_rate']}")
            else:
                logger.warning(f"å¤„ç†éƒ¨åˆ†æˆåŠŸæˆ–å¤±è´¥: {excel_result['status']}")
            
            return result
            
        except Exception as e:
            error_msg = f"å¤„ç†MDå†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            logger.error(error_msg, exc_info=True)
            return {
                "success": False,
                "error": error_msg,
                "stage": "processing",
                "timestamp": timestamp
            }
    
    def process_md_file(self, md_file_path: str) -> Dict[str, Any]:
        """
        å¤„ç†MDæ–‡ä»¶
        
        å‚æ•°:
            md_file_path: MDæ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            å¤„ç†ç»“æœå­—å…¸
        """
        try:
            with open(md_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            filename = Path(md_file_path).name
            return self.process_md_content(content, filename)
            
        except FileNotFoundError:
            return {
                "success": False,
                "error": f"æ‰¾ä¸åˆ°MDæ–‡ä»¶: {md_file_path}",
                "stage": "file_reading"
            }
        except UnicodeDecodeError:
            return {
                "success": False,
                "error": f"MDæ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ä¸ºUTF-8ç¼–ç : {md_file_path}",
                "stage": "file_reading"
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"è¯»å–MDæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                "stage": "file_reading"
            }
    
    def _convert_md_to_api_data(self, parsed_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†MDè§£æç»“æœè½¬æ¢ä¸ºAPIæ•°æ®æ ¼å¼
        ä½¿ç”¨å®Œæ•´çš„è´¢åŠ¡å­—æ®µæ˜ å°„é€»è¾‘
        
        å‚æ•°:
            parsed_result: MDè§£æç»“æœ
            
        è¿”å›:
            APIæ•°æ®æ ¼å¼å­—å…¸
        """
        api_data = {}
        rows = parsed_result.get('rows', [])
        capital_stock_count = 0  # ç”¨äºåŒºåˆ†ä¸¤ä¸ªè³‡æœ¬é‡‘
        
        logger.info(f"å¼€å§‹è½¬æ¢MDè§£æç»“æœï¼Œå…±æœ‰ {len(rows)} è¡Œæ•°æ®")
        
        # æ ¹æ®å®é™…çš„MDè¡¨æ ¼ç»“æ„æ¥æ˜ å°„æ•°æ®
        if rows:
            for i, row in enumerate(rows):
                # è¡¨æ ¼æ ¼å¼ï¼š['', 'å‰æœˆæ®‹é«˜', 'å€Ÿæ–¹é‡‘é¡', 'è²¸æ–¹é‡‘é¡', 'å½“æœˆæ®‹é«˜', 'æ§‹æˆæ¯”']
                # ç¬¬ä¸€åˆ—ï¼ˆç©ºåˆ—åï¼‰åŒ…å«ç§‘ç›®åç§°ï¼Œå½“æœˆæ®‹é«˜åˆ—åŒ…å«æˆ‘ä»¬éœ€è¦çš„æ•°å€¼
                subject_name = None
                value = None
                
                # æŸ¥æ‰¾ç§‘ç›®åç§°å’Œæ•°å€¼
                for key, val in row.items():
                    if key == '' and val:  # ç¬¬ä¸€åˆ—ï¼ˆç©ºåˆ—åï¼‰åŒ…å«ç§‘ç›®åç§°
                        subject_name = val
                    elif key == 'å½“æœˆæ®‹é«˜' and val is not None:  # å½“æœˆæ®‹é«˜åˆ—åŒ…å«æ•°å€¼
                        value = val
                
                if subject_name:
                    # æ¸…ç†ç§‘ç›®åç§°
                    subject_name = self._clean_subject_name(str(subject_name))
                    
                    if not subject_name:
                        continue
                    
                    # ç‰¹æ®Šå¤„ç†è³‡æœ¬é‡‘ï¼ˆå‡ºç°ä¸¤æ¬¡ï¼‰
                    if subject_name == "è³‡æœ¬é‡‘":
                        capital_stock_count += 1
                        if capital_stock_count == 1:
                            field_name = "capital_stock"
                        else:
                            field_name = "capital_stock_duplicate"
                    # å…¶ä»–ç‰¹æ®Šå¤„ç†å’Œæ˜ å°„
                    elif subject_name == "æµå‹•è³‡ç”£åˆè¨ˆ":
                        field_name = "current_assets_total"
                    elif subject_name == "å›ºå®šè³‡ç”£åˆè¨ˆ" or subject_name == "å›ºå®šè³‡ç”¢åˆè¨ˆ":
                        field_name = "fixed_assets_total"
                    elif subject_name == "æµå‹•è² å‚µåˆè¨ˆ":
                        field_name = "current_liabilities_total"
                    elif subject_name == "å›ºå®šè² å‚µåˆè¨ˆ":
                        field_name = "fixed_liabilities_total"
                    elif subject_name == "è² å‚µã®éƒ¨åˆè¨ˆ":
                        field_name = "total_liabilities"
                    elif subject_name == "è³‡æœ¬é‡‘åˆè¨ˆ":
                        field_name = "capital_stock_duplicate"
                    elif subject_name in ["è³‡æœ¬å‰°ä½™é‡‘åˆè¨ˆ", "è³‡æœ¬å‰©ä½™é‡‘åˆè¨ˆ"]:
                        field_name = "capital_surplus_total"
                    elif subject_name == "åˆ©ç›Šå‰°ä½™é‡‘åˆè¨ˆ":
                        field_name = "retained_earnings_total"
                    elif subject_name == "æ ªä¸»è³‡æœ¬åˆè¨ˆ":
                        field_name = "shareholders_equity_total"
                    elif subject_name == "ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ":
                        field_name = "net_assets_total"
                    elif subject_name in ["è² å‚µÂ·ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ", "è² å‚µãƒ»ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ"]:
                        field_name = "total_liabilities_and_equity"
                    else:
                        # ä½¿ç”¨å®Œæ•´æ˜ å°„æŸ¥æ‰¾å¯¹åº”çš„JSONå­—æ®µå
                        field_name = self.japanese_to_field_mapping.get(subject_name)
                    
                    if field_name and value is not None:
                        # è§£ææ•°å€¼
                        if isinstance(value, str):
                            parsed_value = self._parse_numeric_value(value)
                        else:
                            parsed_value = float(value) if value != 0 else 0.0
                        
                        api_data[field_name] = parsed_value
                        logger.debug(f"è¡Œ {i+1}: {subject_name} -> {field_name} = {parsed_value}")
                    else:
                        if not field_name:
                            logger.debug(f"è¡Œ {i+1}: æœªæ‰¾åˆ°æ˜ å°„ - {subject_name}")
                        if value is None:
                            logger.debug(f"è¡Œ {i+1}: æœªæ‰¾åˆ°æ•°å€¼ - {subject_name}")
        
        logger.info(f"è½¬æ¢å®Œæˆï¼ŒæˆåŠŸæ˜ å°„ {len(api_data)} ä¸ªå­—æ®µ")
        logger.debug(f"è½¬æ¢çš„APIæ•°æ®: {json.dumps(api_data, ensure_ascii=False, indent=2)}")
        return api_data
    
    def _parse_numeric_value(self, value_str: str) -> float:
        """
        è§£ææ•°å€¼å­—ç¬¦ä¸²
        
        å‚æ•°:
            value_str: æ•°å€¼å­—ç¬¦ä¸²ï¼ˆå¯èƒ½åŒ…å«é€—å·ã€è´Ÿå·ç­‰ï¼‰
            
        è¿”å›:
            è§£æåçš„æµ®ç‚¹æ•°
        """
        if not value_str or str(value_str).strip() == "":
            return 0.0
            
        # å»é™¤ç©ºæ ¼
        value_str = str(value_str).strip()
        
        # å¤„ç†è´Ÿæ•°ï¼ˆå¯èƒ½æ˜¯è´Ÿå·å¼€å¤´ï¼‰
        is_negative = value_str.startswith('-') or value_str.startswith('âˆ’')
        
        # å»é™¤æ‰€æœ‰éæ•°å­—å­—ç¬¦ï¼ˆä¿ç•™å°æ•°ç‚¹ï¼‰
        import re
        value_str = re.sub(r'[^0-9.-]', '', value_str)
        
        try:
            value = float(value_str)
            return -abs(value) if is_negative else value
        except ValueError:
            logger.warning(f"æ— æ³•è§£ææ•°å€¼: {value_str}")
            return 0.0
    
    def _build_japanese_mapping(self) -> Dict[str, str]:
        """
        ä»mapping_configæ„å»ºæ—¥æ–‡ç§‘ç›®ååˆ°JSONå­—æ®µçš„æ˜ å°„
        
        è¿”å›:
            æ—¥æ–‡ç§‘ç›®ååˆ°JSONå­—æ®µåçš„æ˜ å°„å­—å…¸
        """
        mapping = {}
        
        # ä»CELL_DESCRIPTIONSä¸­æå–æ—¥æ–‡åç§°
        for cell, description in CELL_DESCRIPTIONS.items():
            # æå–æ—¥æ–‡éƒ¨åˆ†ï¼ˆæ‹¬å·å‰çš„å†…å®¹ï¼‰
            japanese_name = description.split(' (')[0].strip()
            
            # æŸ¥æ‰¾å¯¹åº”çš„JSONå­—æ®µ
            for field, cell_ref in TRIAL_BALANCE_MAPPING.items():
                if cell_ref == cell:
                    mapping[japanese_name] = field
                    break
        
        # æ·»åŠ ä¸€äº›ç‰¹æ®Šçš„æ˜ å°„ï¼ˆå¤„ç†æ ¼å¼å·®å¼‚ï¼‰
        special_mappings = {
            "ç¾é‡‘åŠã³é é‡‘åˆè¨ˆ": "cash_and_deposits_total",
            "å£²ä¸Šå‚µæ¨©åˆè¨ˆ": "receivables_total",
            "ãã®ä»–æµå‹•è³‡ç”£åˆè¨ˆ": "other_current_assets_total",
            "æµå‹•è³‡ç”£åˆè¨ˆ": "current_assets_total",
            "æœ‰å½¢å›ºå®šè³‡ç”£åˆè¨ˆ": "tangible_fixed_assets_total",
            "æŠ•è³‡ãã®ä»–ã®è³‡ç”£åˆè¨ˆ": "investment_assets_total",
            "å›ºå®šè³‡ç”¢åˆè¨ˆ": "fixed_assets_total",  # æ³¨æ„æ˜¯è³‡ç”¢ä¸æ˜¯è³‡ç”£
            "è³‡ç”£ã®éƒ¨åˆè¨ˆ": "total_assets",
            "ãã®ä»–æµå‹•è² å‚µåˆè¨ˆ": "other_current_liabilities_total",
            "æµå‹•è² å‚µåˆè¨ˆ": "current_liabilities_total",
            "å›ºå®šè² å‚µåˆè¨ˆ": "fixed_liabilities_total",
            "è² å‚µã®éƒ¨åˆè¨ˆ": "total_liabilities",
            "è³‡æœ¬é‡‘åˆè¨ˆ": "capital_stock_duplicate",  # ç‰¹æ®Šå¤„ç†
            "è³‡æœ¬å‰°ä½™é‡‘åˆè¨ˆ": "capital_surplus_total",
            "åˆ©ç›Šå‰©ä½™é‡‘åˆè¨ˆ": "retained_earnings_total",  # æ³¨æ„æ˜¯å‰©ä½™ä¸æ˜¯å‰°ä½™
            "æ ªä¸»è³‡æœ¬åˆè¨ˆ": "shareholders_equity_total",
            "ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ": "net_assets_total",
            "è² å‚µÂ·ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ": "total_liabilities_and_equity",
            "è² å‚µãƒ»ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ": "total_liabilities_and_equity",  # å¤„ç†ä¸åŒçš„ä¸­ç‚¹ç¬¦å·
            "ç¹°è¶Šåˆ©ç›Šå‰©ä½™é‡‘": "retained_earnings",  # æ·»åŠ ç•™å­˜æ”¶ç›Šæ˜ å°„
            # ä¸­æ–‡æ˜ å°„ï¼ˆä¿ç•™åŸæœ‰çš„æ˜ å°„ï¼‰
            "ç°é‡‘": "cash",
            "é“¶è¡Œå­˜æ¬¾": "ordinary_deposits", 
            "ç°é‡‘åŠå­˜æ¬¾åˆè®¡": "cash_and_deposits_total",
            "ç°é‡‘åŠé¢„é‡‘åˆè®¡": "cash_and_deposits_total",
            "åº”æ”¶è´¦æ¬¾": "accounts_receivable",
            "åº”æ”¶ç¥¨æ®": "notes_receivable",
            "å…¶ä»–åº”æ”¶æ¬¾": "other_receivables",
            "åº”æ”¶å€ºæƒåˆè®¡": "receivables_total",
            "åº“å­˜": "inventory",
            "åº“å­˜å•†å“": "inventory",
            "å…¶ä»–æµåŠ¨èµ„äº§": "other_current_assets",
            "æµåŠ¨èµ„äº§åˆè®¡": "current_assets_total",
            "å»ºç­‘ç‰©": "buildings",
            "æœºæ¢°è®¾å¤‡": "machinery_equipment",
            "è½¦è¾†": "vehicles",
            "æœ‰å½¢å›ºå®šèµ„äº§åˆè®¡": "tangible_fixed_assets_total",
            "æŠ•èµ„æœ‰ä»·è¯åˆ¸": "investment_securities",
            "æŠ•èµ„å…¶ä»–èµ„äº§åˆè®¡": "investment_assets_total",
            "å›ºå®šèµ„äº§åˆè®¡": "fixed_assets_total",
            "èµ„äº§åˆè®¡": "total_assets",
            "æ€»èµ„äº§": "total_assets",
            "åº”ä»˜è´¦æ¬¾": "accounts_payable",
            "åº”ä»˜ç¥¨æ®": "notes_payable",
            "çŸ­æœŸå€Ÿæ¬¾": "short_term_loans",
            "å…¶ä»–æµåŠ¨è´Ÿå€º": "other_current_liabilities",
            "æµåŠ¨è´Ÿå€ºåˆè®¡": "current_liabilities_total",
            "é•¿æœŸå€Ÿæ¬¾": "long_term_loans",
            "å›ºå®šè´Ÿå€ºåˆè®¡": "fixed_liabilities_total",
            "è´Ÿå€ºåˆè®¡": "total_liabilities",
            "æ€»è´Ÿå€º": "total_liabilities",
            "èµ„æœ¬é‡‘": "capital_stock",
            "èµ„æœ¬å…¬ç§¯": "capital_surplus",
            "åˆ©æ¶¦å…¬ç§¯": "retained_earnings",
            "è‚¡ä¸œæƒç›Šåˆè®¡": "shareholders_equity_total",
            "çº¯èµ„äº§åˆè®¡": "net_assets_total",
            "è´Ÿå€ºåŠèµ„æœ¬åˆè®¡": "total_liabilities_and_equity",
            "è´Ÿå€ºå’Œæƒç›Šåˆè®¡": "total_liabilities_and_equity"
        }
        
        mapping.update(special_mappings)
        
        logger.debug("æ˜ å°„å…³ç³»æ„å»ºå®Œæˆ:")
        for jp, en in mapping.items():
            logger.debug(f"  {jp} -> {en}")
            
        return mapping
    
    def _clean_subject_name(self, name: str) -> str:
        """
        æ¸…ç†ç§‘ç›®åç§°
        
        å‚æ•°:
            name: åŸå§‹ç§‘ç›®åç§°
            
        è¿”å›:
            æ¸…ç†åçš„ç§‘ç›®åç§°
        """
        if not name:
            return ""
            
        # å»é™¤å‰åç©ºæ ¼
        name = name.strip()
        
        # å»é™¤ã€ã€‘ç¬¦å·
        name = name.replace('ã€', '').replace('ã€‘', '')
        
        # ç»Ÿä¸€å…¨è§’åŠè§’
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šè½¬æ¢
        
        return name
    
    def _map_md_field_to_api_field(self, md_field: str) -> Optional[str]:
        """
        å°†MDè¡¨æ ¼å­—æ®µåæ˜ å°„åˆ°APIå­—æ®µå
        
        å‚æ•°:
            md_field: MDè¡¨æ ¼ä¸­çš„å­—æ®µå
            
        è¿”å›:
            å¯¹åº”çš„APIå­—æ®µåï¼Œå¦‚æœæ²¡æœ‰æ˜ å°„åˆ™è¿”å›None
        """
        # æ„å»ºå®Œæ•´çš„æ—¥æ–‡åˆ°è‹±æ–‡æ˜ å°„ï¼ˆå¦‚æœè¿˜æ²¡æœ‰æ„å»ºï¼‰
        if not hasattr(self, 'japanese_to_field_mapping'):
            self.japanese_to_field_mapping = self._build_japanese_mapping()
            logger.info(f"å·²æ„å»º {len(self.japanese_to_field_mapping)} ä¸ªæ—¥æ–‡åˆ°å­—æ®µçš„æ˜ å°„")
        
        # æ¸…ç†å­—æ®µå
        cleaned_field = self._clean_subject_name(md_field)
        
        # å…ˆå°è¯•ç›´æ¥åŒ¹é…
        if cleaned_field in self.japanese_to_field_mapping:
            return self.japanese_to_field_mapping[cleaned_field]
        
        # å¦‚æœæ²¡æœ‰ç›´æ¥åŒ¹é…ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
        for key, value in self.japanese_to_field_mapping.items():
            if key in cleaned_field or cleaned_field in key:
                return value
        
        # å¦‚æœéƒ½æ²¡æœ‰åŒ¹é…ï¼Œè¿”å›None
        logger.debug(f"æœªæ‰¾åˆ°å­—æ®µæ˜ å°„: {md_field} (æ¸…ç†å: {cleaned_field})")
        return None
    
    def get_output_file(self, output_filename: str) -> Optional[str]:
        """
        è·å–è¾“å‡ºæ–‡ä»¶çš„å®Œæ•´è·¯å¾„
        
        å‚æ•°:
            output_filename: è¾“å‡ºæ–‡ä»¶å
            
        è¿”å›:
            å®Œæ•´æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨è¿”å›None
        """
        file_path = self.output_dir / output_filename
        return str(file_path) if file_path.exists() else None


def main():
    """æµ‹è¯•MDåˆ°Excelå¤„ç†åŠŸèƒ½"""
    processor = MDToExcelProcessor()
    
    # æµ‹è¯•å†…å®¹
    test_content = """
# èµ„äº§è´Ÿå€ºè¡¨

| ç§‘ç›® | é‡‘é¢ |
|------|------|
| ç°é‡‘ | 1000000 |
| é“¶è¡Œå­˜æ¬¾ | 5000000 |
| åº”æ”¶è´¦æ¬¾ | 2000000 |
| åº“å­˜å•†å“ | 3000000 |
| æµåŠ¨èµ„äº§åˆè®¡ | 11000000 |
| å»ºç­‘ç‰© | 8000000 |
| æœºæ¢°è®¾å¤‡ | 2000000 |
| å›ºå®šèµ„äº§åˆè®¡ | 10000000 |
| æ€»èµ„äº§ | 21000000 |
"""
    
    try:
        result = processor.process_md_content(test_content, "test.md")
        
        print("\n=== MDåˆ°Excelå¤„ç†ç»“æœ ===")
        print(f"âœ… å¤„ç†çŠ¶æ€: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
        
        if result['success']:
            print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {result['output_filename']}")
            print(f"ğŸ“Š MDè§£æ: {result['md_parsing']['rows_count']} è¡Œæ•°æ®")
            print(f"ğŸ“ˆ Excelå†™å…¥: {result['excel_writing']['success_rate']}")
        else:
            print(f"âŒ é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    main()