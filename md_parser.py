#!/usr/bin/env python3
"""
MDè´¢åŠ¡æŠ¥è¡¨è§£ææ¨¡å—
å°†MDæ ¼å¼çš„è´¢åŠ¡æŠ¥è¡¨è½¬æ¢ä¸ºJSONæ ¼å¼
"""

import re
import json
import logging
from typing import Dict, Any, Optional, Tuple
from pathlib import Path
from bs4 import BeautifulSoup
from mapping_config import TRIAL_BALANCE_MAPPING, CELL_DESCRIPTIONS

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MDFinancialParser:
    """
    è§£æMDæ ¼å¼çš„è´¢åŠ¡æŠ¥è¡¨å¹¶è½¬æ¢ä¸ºJSONæ ¼å¼
    """
    
    def __init__(self):
        """åˆå§‹åŒ–è§£æå™¨"""
        self.japanese_to_field_mapping = self._build_japanese_mapping()
        logger.info(f"å·²æ„å»º {len(self.japanese_to_field_mapping)} ä¸ªæ—¥æ–‡åˆ°å­—æ®µçš„æ˜ å°„")
        
    def _build_japanese_mapping(self) -> Dict[str, str]:
        """
        ä»mapping_configæ„å»ºæ—¥æ–‡ç§‘ç›®ååˆ°JSONå­—æ®µçš„æ˜ å°„
        
        è¿”å›:
            æ—¥æ–‡ç§‘ç›®ååˆ°JSONå­—æ®µåçš„æ˜ å°„å­—å…¸
        """
        mapping = {}
        
        # ä»CELL_DESCRIPTIONSä¸­æå–æ—¥æ–‡åç§°
        for cell, description in CELL_DESCRIPTIONS.items():
            # æå–æ—¥æ–‡éƒ¨åˆ†ï¼ˆæ‹¬å·å‰çš„å†…å®¹ï¼‰
            japanese_name = description.split(' (')[0].strip()
            
            # æŸ¥æ‰¾å¯¹åº”çš„JSONå­—æ®µ
            for field, cell_ref in TRIAL_BALANCE_MAPPING.items():
                if cell_ref == cell:
                    mapping[japanese_name] = field
                    break
        
        # æ·»åŠ ä¸€äº›ç‰¹æ®Šçš„æ˜ å°„ï¼ˆå¤„ç†æ ¼å¼å·®å¼‚ï¼‰
        special_mappings = {
            "ç¾é‡‘åŠã³é é‡‘åˆè¨ˆ": "cash_and_deposits_total",
            "å£²ä¸Šå‚µæ¨©åˆè¨ˆ": "receivables_total",
            "ãã®ä»–æµå‹•è³‡ç”£åˆè¨ˆ": "other_current_assets_total",
            "æµå‹•è³‡ç”£åˆè¨ˆ": "current_assets_total",
            "æœ‰å½¢å›ºå®šè³‡ç”£åˆè¨ˆ": "tangible_fixed_assets_total",
            "æŠ•è³‡ãã®ä»–ã®è³‡ç”£åˆè¨ˆ": "investment_assets_total",
            "å›ºå®šè³‡ç”¢åˆè¨ˆ": "fixed_assets_total",  # æ³¨æ„æ˜¯è³‡ç”¢ä¸æ˜¯è³‡ç”£
            "è³‡ç”£ã®éƒ¨åˆè¨ˆ": "total_assets",
            "ãã®ä»–æµå‹•è² å‚µåˆè¨ˆ": "other_current_liabilities_total",
            "æµå‹•è² å‚µåˆè¨ˆ": "current_liabilities_total",
            "å›ºå®šè² å‚µåˆè¨ˆ": "fixed_liabilities_total",
            "è² å‚µã®éƒ¨åˆè¨ˆ": "total_liabilities",
            "è³‡æœ¬é‡‘åˆè¨ˆ": "capital_stock_duplicate",  # ç‰¹æ®Šå¤„ç†
            "è³‡æœ¬å‰°ä½™é‡‘åˆè¨ˆ": "capital_surplus_total",
            "åˆ©ç›Šå‰©ä½™é‡‘åˆè¨ˆ": "retained_earnings_total",  # æ³¨æ„æ˜¯å‰©ä½™ä¸æ˜¯å‰°ä½™
            "æ ªä¸»è³‡æœ¬åˆè¨ˆ": "shareholders_equity_total",
            "ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ": "net_assets_total",
            "è² å‚µÂ·ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ": "total_liabilities_and_equity",
            "è² å‚µãƒ»ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ": "total_liabilities_and_equity",  # å¤„ç†ä¸åŒçš„ä¸­ç‚¹ç¬¦å·
            "ç¹°è¶Šåˆ©ç›Šå‰©ä½™é‡‘": "retained_earnings"  # æ·»åŠ ç•™å­˜æ”¶ç›Šæ˜ å°„
        }
        
        mapping.update(special_mappings)
        
        logger.debug("æ˜ å°„å…³ç³»æ„å»ºå®Œæˆ:")
        for jp, en in mapping.items():
            logger.debug(f"  {jp} -> {en}")
            
        return mapping
    
    def _clean_subject_name(self, name: str) -> str:
        """
        æ¸…ç†ç§‘ç›®åç§°
        
        å‚æ•°:
            name: åŸå§‹ç§‘ç›®åç§°
            
        è¿”å›:
            æ¸…ç†åçš„ç§‘ç›®åç§°
        """
        if not name:
            return ""
            
        # å»é™¤å‰åç©ºæ ¼
        name = name.strip()
        
        # å»é™¤ã€ã€‘ç¬¦å·
        name = name.replace('ã€', '').replace('ã€‘', '')
        
        # ç»Ÿä¸€å…¨è§’åŠè§’
        # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šè½¬æ¢
        
        return name
    
    def _parse_numeric_value(self, value_str: str) -> float:
        """
        è§£ææ•°å€¼å­—ç¬¦ä¸²
        
        å‚æ•°:
            value_str: æ•°å€¼å­—ç¬¦ä¸²ï¼ˆå¯èƒ½åŒ…å«é€—å·ã€è´Ÿå·ç­‰ï¼‰
            
        è¿”å›:
            è§£æåçš„æµ®ç‚¹æ•°
        """
        if not value_str or value_str.strip() == "":
            return 0.0
            
        # å»é™¤ç©ºæ ¼
        value_str = value_str.strip()
        
        # å¤„ç†è´Ÿæ•°ï¼ˆå¯èƒ½æ˜¯è´Ÿå·å¼€å¤´ï¼‰
        is_negative = value_str.startswith('-') or value_str.startswith('âˆ’')
        
        # å»é™¤æ‰€æœ‰éæ•°å­—å­—ç¬¦ï¼ˆä¿ç•™å°æ•°ç‚¹ï¼‰
        value_str = re.sub(r'[^0-9.-]', '', value_str)
        
        try:
            value = float(value_str)
            return -abs(value) if is_negative else value
        except ValueError:
            logger.warning(f"æ— æ³•è§£ææ•°å€¼: {value_str}")
            return 0.0
    
    def parse_md_file(self, md_file_path: str) -> Dict[str, Any]:
        """
        è§£æMDæ–‡ä»¶å¹¶æå–è´¢åŠ¡æ•°æ®
        
        å‚æ•°:
            md_file_path: MDæ–‡ä»¶è·¯å¾„
            
        è¿”å›:
            JSONæ ¼å¼çš„è´¢åŠ¡æ•°æ®
        """
        logger.info(f"å¼€å§‹è§£æMDæ–‡ä»¶: {md_file_path}")
        
        # è¯»å–MDæ–‡ä»¶
        with open(md_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ä½¿ç”¨BeautifulSoupè§£æHTMLè¡¨æ ¼
        soup = BeautifulSoup(content, 'html.parser')
        tables = soup.find_all('table')
        
        if not tables:
            raise ValueError("MDæ–‡ä»¶ä¸­æœªæ‰¾åˆ°è¡¨æ ¼")
        
        logger.info(f"æ‰¾åˆ° {len(tables)} ä¸ªè¡¨æ ¼")
        
        # è§£æç¬¬ä¸€ä¸ªè¡¨æ ¼ï¼ˆè²¸å€Ÿå¯¾ç…§è¡¨ï¼‰
        result = self._parse_balance_sheet_table(tables[0])
        
        # éªŒè¯ç»“æœ
        self._validate_result(result)
        
        return result
    
    def _parse_balance_sheet_table(self, table) -> Dict[str, Any]:
        """
        è§£æèµ„äº§è´Ÿå€ºè¡¨è¡¨æ ¼
        
        å‚æ•°:
            table: BeautifulSoupçš„tableå¯¹è±¡
            
        è¿”å›:
            æå–çš„æ•°æ®å­—å…¸
        """
        result = {}
        capital_stock_count = 0  # ç”¨äºåŒºåˆ†ä¸¤ä¸ªè³‡æœ¬é‡‘
        
        # éå†æ‰€æœ‰è¡Œ
        rows = table.find_all('tr')
        logger.info(f"è¡¨æ ¼åŒ…å« {len(rows)} è¡Œ")
        
        for i, row in enumerate(rows):
            cells = row.find_all('td')
            
            # è·³è¿‡è¡¨å¤´æˆ–ä¸å®Œæ•´çš„è¡Œ
            if len(cells) < 5:
                continue
            
            # æå–ç§‘ç›®åç§°ï¼ˆç¬¬1åˆ—ï¼‰å’Œå½“æœˆæ®‹é«˜ï¼ˆç¬¬5åˆ—ï¼‰
            subject_name = cells[0].get_text()
            value_text = cells[4].get_text()  # ç´¢å¼•4æ˜¯ç¬¬5åˆ—
            
            # æ¸…ç†ç§‘ç›®åç§°
            subject_name = self._clean_subject_name(subject_name)
            
            if not subject_name:
                continue
            
            # ç‰¹æ®Šå¤„ç†è³‡æœ¬é‡‘ï¼ˆå‡ºç°ä¸¤æ¬¡ï¼‰
            if subject_name == "è³‡æœ¬é‡‘":
                capital_stock_count += 1
                if capital_stock_count == 1:
                    field_name = "capital_stock"
                else:
                    field_name = "capital_stock_duplicate"
            # ç‰¹æ®Šå¤„ç†ä¸€äº›æ²¡æœ‰ã€ã€‘çš„æ€»è®¡é¡¹ç›®
            elif subject_name == "æµå‹•è³‡ç”£åˆè¨ˆ":
                field_name = "current_assets_total"
            elif subject_name == "å›ºå®šè³‡ç”¢åˆè¨ˆ":
                field_name = "fixed_assets_total"
            elif subject_name == "æµå‹•è² å‚µåˆè¨ˆ":
                field_name = "current_liabilities_total"
            elif subject_name == "å›ºå®šè² å‚µåˆè¨ˆ":
                field_name = "fixed_liabilities_total"
            elif subject_name == "è² å‚µã®éƒ¨åˆè¨ˆ":
                field_name = "total_liabilities"
            elif subject_name == "è³‡æœ¬é‡‘åˆè¨ˆ":
                field_name = "capital_stock_duplicate"
            elif subject_name == "è³‡æœ¬å‰°ä½™é‡‘åˆè¨ˆ" or subject_name == "è³‡æœ¬å‰©ä½™é‡‘åˆè¨ˆ":
                field_name = "capital_surplus_total"
            elif subject_name == "åˆ©ç›Šå‰°ä½™é‡‘åˆè¨ˆ":
                field_name = "retained_earnings_total"
            elif subject_name == "æ ªä¸»è³‡æœ¬åˆè¨ˆ":
                field_name = "shareholders_equity_total"
            elif subject_name == "ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ":
                field_name = "net_assets_total"
            elif subject_name == "è² å‚µÂ·ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ" or subject_name == "è² å‚µãƒ»ç´”è³‡ç”£ã®éƒ¨åˆè¨ˆ":
                field_name = "total_liabilities_and_equity"
            else:
                # æŸ¥æ‰¾å¯¹åº”çš„JSONå­—æ®µå
                field_name = self.japanese_to_field_mapping.get(subject_name)
            
            if field_name:
                # è§£ææ•°å€¼
                value = self._parse_numeric_value(value_text)
                result[field_name] = value
                logger.debug(f"è¡Œ {i+1}: {subject_name} -> {field_name} = {value}")
            else:
                logger.debug(f"è¡Œ {i+1}: æœªæ‰¾åˆ°æ˜ å°„ - {subject_name}")
        
        return result
    
    def _validate_result(self, result: Dict[str, Any]):
        """
        éªŒè¯è§£æç»“æœçš„å®Œæ•´æ€§
        
        å‚æ•°:
            result: è§£æç»“æœå­—å…¸
        """
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = set(TRIAL_BALANCE_MAPPING.keys())
        extracted_fields = set(result.keys())
        
        missing_fields = required_fields - extracted_fields
        extra_fields = extracted_fields - required_fields
        
        if missing_fields:
            logger.warning(f"ç¼ºå°‘ {len(missing_fields)} ä¸ªå­—æ®µ: {missing_fields}")
        
        if extra_fields:
            logger.warning(f"å¤šä½™ {len(extra_fields)} ä¸ªå­—æ®µ: {extra_fields}")
        
        logger.info(f"æˆåŠŸæå– {len(extracted_fields)} / {len(required_fields)} ä¸ªå­—æ®µ")
    
    def save_to_json(self, data: Dict[str, Any], output_path: str):
        """
        å°†æ•°æ®ä¿å­˜ä¸ºJSONæ–‡ä»¶
        
        å‚æ•°:
            data: è¦ä¿å­˜çš„æ•°æ®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """æµ‹è¯•MDè§£æåŠŸèƒ½"""
    parser = MDFinancialParser()
    
    # è§£æMDæ–‡ä»¶
    md_file = "corrected_financial_statement.md"
    
    try:
        data = parser.parse_md_file(md_file)
        
        # ä¿å­˜ä¸ºJSON
        output_file = "parsed_financial_data.json"
        parser.save_to_json(data, output_file)
        
        print(f"\nâœ… æˆåŠŸè§£æMDæ–‡ä»¶å¹¶ç”ŸæˆJSON")
        print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
        print(f"ğŸ“Š æå–å­—æ®µæ•°: {len(data)}")
        
    except Exception as e:
        print(f"\nâŒ è§£æå¤±è´¥: {str(e)}")
        logger.error(f"è§£æå¤±è´¥: {str(e)}", exc_info=True)


if __name__ == "__main__":
    main()